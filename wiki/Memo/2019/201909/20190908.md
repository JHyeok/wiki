### 20190908
---

#### 머신러닝

MLPClassifier(hidden_layer_size, activation)\
MLPClassifier에서 activaion은 거의 default를 사용함\
ex) hidden_layer_size = (3,2) : 첫번쨰 은닉노드 개수 = 3, 두번쨰 은닉노드 개수 = 2\
4층까지만 지원함 = (10, 9, 8, 7) ok / (10, 9, 8, 7, 6) X\
5층이상 쓰려면 심층신경망 입문하는 사람들을 위한 딥러닝 프레임워크를 써야 하고 keras 추천하심.

**ConvergenceWarning**\
ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200)
- 수렴이 되지 않았다.
- 모델 복잡도에 비해서 데이터 크기가 불충분하다.
- SVR, NN에서 보통 많이 뜬다.

**ConvergenceWarning 해결법**
- 큰 데이터를 사용
- 상대적으로 덜 복잡한 모델 사용
- max_iter 늘리기

ex) 예지정비 - 센서를 바탕으로 예측\
클래스: 정상/고장 => 분류\
언제고장? => 예측\

**군집화**\
코사인 유사도 => 방향성O, 크기X => 상품 구매 기준으로 군집화(추천 시스템)\

**모델 선정**\
일반적으로 복잡한 모델일 수록 시간이 오래 걸리고, 과적합 가능성이 크다. 필요한 데이터 양이 많다. 충분한 데이터가 있다는 가정하에 성능은 충분히 좋다.\
단순한 모델은 복잡한 모델과 반대이다.\

k-최근접이웃: 시간이 적게 걸리고, 베이스 라인 모델 구축에 주로 사용\
의사결정나무는 스케일링을 해도 그만 안해도 그만인데, K-NN은 해주는게 효과적이다.\
신경망과 K-NN은 스케일링이 필요하고, 이진형은 별로 좋지않고, 연속형에 좋다고 한다.

**그리드 서치**\
시간이 굉장히 오래걸리는 작업이다.

**결측치 처리**\
결측(missing) = 값이 없음
- Null = 값이 없는게 값
- NaN = 값이 있어야 하는데 없는 값\
결측치 문제는데이터에 결측치가 있어서, 모델 학습이 되지 않는 문제

해결방법
- 행 제거: 가장 간단하고 가장 확실, 남은 레코드의 수가 충분히 있을 때 해야 한다(러닝커브 그려서 확인).
- 열 제거: 특정 열에만 결측이 많은 경우, 지우고자 한 컬럼이 중요하지 않아야 한다.
- 대표 값 활용: 행 제거와 열제거를 수행할 수 없을 떄 수행

행열간 계산, 백터 계산에 쓰이는 모듈 numpy\
pandas에서는 numpy에 있는 자료구조 or 계산식 사용\
pandas는 sklearn에서 주로 입력으로 쓰임\
sklearn의 출력은 numpy자료형임(ndarray)\
그래서 predict(x)를 했을 떄, numpy에 있는 ndarray가 출력\
numpy, pandas, sklearn을 공부하면 됨

pandas의 더미화를 수행할 때, 즉, `pd.get_dummies`를 사용할 때 `drop_first = True`하는게 좋음.

**성능을 올리는 방법**
- 모델, 파라미터를 변경하는 방법
- 성능을 위한 전처리 - 일반적으로 이 방법이 성능향상이 쉽다.

**재샘플링**\
보통은 오버샘플링보다 언더샘플링을 더 많이 사용한다.

전부 이진형이면 카이제곱 통계량을 사용하고, 그 외에는 상호 정보량 사용하는 것을 추천.

프로젝트를 하시는 사람들은 python, 머신러닝 주요 모듈들을 학습하고 나서, 관련 문헌을 찾아가면서 공부하는게 가장 빠르다.

---
#### 참고

패스트캠퍼스 2주 안에 Data Scientist되기